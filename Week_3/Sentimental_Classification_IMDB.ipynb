{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "position": {
        "height": "553px",
        "left": "792px",
        "right": "61px",
        "top": "71px",
        "width": "375px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oq4UnWajC9u"
      },
      "source": [
        "# Sentiment Classification\n",
        "\n",
        "### Task\n",
        "* IMDB 영화사이트에서 50000개의 영화평을 가지고 positive/negative인지 구분해보자.\n",
        "* 데이터 불러오기를 제외한 딥러닝 트레이닝 과정을 직접 구현해보는 것이 목표 입니다.\n",
        "\n",
        "### Dataset\n",
        "* [IMDB datasets](https://www.imdb.com/interfaces/)\n",
        "\n",
        "### Base code\n",
        "* Dataset: train, val, test로 split\n",
        "* Input data shape: (`batch_size`, `max_sequence_length`)\n",
        "* Output data shape: (`batch_size`, 1)\n",
        "* Architecture:\n",
        "  * RNN을 이용한 간단한 classification 모델 가이드\n",
        "  * `Embedding` - `SimpleRNN` - `Dense (with Sigmoid)`\n",
        "  * [`tf.keras.layers`](https://www.tensorflow.org/api_docs/python/tf/keras/layers) 사용\n",
        "* Training\n",
        "  * `model.fit` 사용\n",
        "* Evaluation\n",
        "  * `model.evaluate` 사용 for test dataset\n",
        "\n",
        "### Try some techniques\n",
        "* Training-epochs 조절\n",
        "* Change model architectures (Custom model)\n",
        "  * Use another cells (LSTM, GRU, etc.)\n",
        "  * Use dropout layers\n",
        "* Embedding size 조절\n",
        "  * 또는 one-hot vector로 학습\n",
        "* Number of words in the vocabulary 변화\n",
        "* `pad` 옵션 변화\n",
        "* Data augmentation (if possible)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKq6mIljjC9v"
      },
      "source": [
        "## 자연어처리에 관한 work flow\n",
        "\n",
        "The flowchart of the algorithm is roughly:\n",
        "\n",
        "<img src=\"https://user-images.githubusercontent.com/11681225/46912373-d2a3a800-cfae-11e8-8201-ef17b65834f5.png\" alt=\"natural_language_flowchart\" style=\"width: 300px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW9rRFr4jC9w"
      },
      "source": [
        "## Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbt0_EpOvL6C"
      },
      "source": [
        "use_colab = True\n",
        "assert use_colab in [True, False]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibO_zjJmvN3s"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-03-04T06:05:42.026345Z",
          "start_time": "2019-03-04T06:05:40.302942Z"
        },
        "id": "ct7ZVZ2EjC9x"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "import os\n",
        "import time\n",
        "import shutil\n",
        "import tarfile\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e3ucn5_jC90"
      },
      "source": [
        "## Load Data\n",
        "\n",
        "* IMDB에서 다운받은 총 50000개의 영화평을 사용한다.\n",
        "* `tf.keras.datasets`에 이미 잘 가공된 데이터 셋이 있으므로 쉽게 다운받아 사용할 수 있다.\n",
        "* 원래는 text 데이터이지만 `tf.keras.datasets.imdb`는 이미 Tokenizing이 되어있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-03-04T06:05:42.083083Z",
          "start_time": "2019-03-04T06:05:42.075925Z"
        },
        "id": "DKOg8JCsjC91"
      },
      "source": [
        "# Load training and eval data from tf.keras\n",
        "imdb = tf.keras.datasets.imdb\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
        "train_labels = train_labels.astype(np.float64)\n",
        "test_labels = test_labels.astype(np.float64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-03-04T06:05:48.627470Z",
          "start_time": "2019-03-04T06:05:48.619679Z"
        },
        "id": "7mL9LbzXjC96"
      },
      "source": [
        "print(\"Train-set size: \", len(train_data))\n",
        "print(\"Test-set size:  \", len(test_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0_MzKDJjC9-"
      },
      "source": [
        "### Data 출력\n",
        "* 데이터셋을 바로 불러왔을때 출력되는 데이터를 확인해보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkWxsmedjC9_"
      },
      "source": [
        "print(train_data[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxOl00BUjC-C"
      },
      "source": [
        "print(\"sequence length: {}\".format(len(train_data[1])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtrDXZZ3jC-F"
      },
      "source": [
        "* Label정보를 확인해보자\n",
        "  * 0.0 for a negative sentiment 부정적인 리뷰\n",
        "  * 1.0 for a positive sentiment 긍정적인 리뷰"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-03-04T06:05:51.490655Z",
          "start_time": "2019-03-04T06:05:51.486122Z"
        },
        "id": "pAQISHYVjC-G"
      },
      "source": [
        "# negative sample\n",
        "index = 1\n",
        "print(\"text: {}\\n\".format(train_data[index]))\n",
        "print(\"label: {}\".format(train_labels[index]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-03-04T06:05:52.735239Z",
          "start_time": "2019-03-04T06:05:52.731203Z"
        },
        "id": "aE-lF_gqjC-K"
      },
      "source": [
        "# positive sample\n",
        "index = 200\n",
        "print(\"text: {}\\n\".format(train_data[index]))\n",
        "print(\"label: {}\".format(train_labels[index]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqlZw3GNjC-Q"
      },
      "source": [
        "## Prepare dataset\n",
        "\n",
        "### Convert the integers back to words\n",
        "\n",
        "* 실제 우리가 다루고 있는 데이터가 진짜 리뷰데이터인지 확인해보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUX_-fu3jC-Q"
      },
      "source": [
        "# A dictionary mapping words to an integer index\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# The first indices are reserved\n",
        "word_index = {k:(v+3) for k,v in word_index.items()}\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2  # unknown\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "  return ' '.join([reverse_word_index.get(i, '?') for i in text])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQd9gEAqjC-S"
      },
      "source": [
        "#### Text data 출력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-ss_usJjC-T"
      },
      "source": [
        "print(train_data[5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZsvB20qjC-V"
      },
      "source": [
        "decode_review(train_data[5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJyBVg01TM0Y"
      },
      "source": [
        "print(train_labels[5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8yYy2OPjC-a"
      },
      "source": [
        "### Padding and truncating data using pad sequences\n",
        "* 전부 길이가 다른 리뷰들의 길이를 통일해주자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb0_NqMZjC-a"
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU6L4MjLjC-c"
      },
      "source": [
        "num_seq_length = np.array([len(tokens) for tokens in list(train_data) + list(test_data)])\n",
        "train_seq_length = np.array([len(tokens) for tokens in train_data], dtype=np.int32)\n",
        "test_seq_length = np.array([len(tokens) for tokens in test_data], dtype=np.int32)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPg8nfTvjC-f"
      },
      "source": [
        "max_seq_length = #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmIjHB2CAzMv"
      },
      "source": [
        "* Max length보다 작은 리뷰의 퍼센트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6OsdVicjC-h"
      },
      "source": [
        "print(np.sum(num_seq_length < max_seq_length) / len(num_seq_length))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjzECbvIjC-k"
      },
      "source": [
        "* `max_seq_length`을 256으로 설정하면 전체 데이터 셋의 70%를 커버할 수 있다.\n",
        "* 30% 정도의 데이터가 256 단어가 넘는 문장으로 이루어져 있다.\n",
        "* 보통 미리 정한 `max_seq_length`를 넘어가는 문장의 데이터는 *truncate* 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mygycLN_jC-k"
      },
      "source": [
        "# padding 옵션은 두 가지가 있다.\n",
        "pad = 'pre'\n",
        "# pad = 'post'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-03-04T06:07:16.640655Z",
          "start_time": "2019-03-04T06:07:16.607400Z"
        },
        "id": "nyIeOTuujC-m"
      },
      "source": [
        "train_data_pad = pad_sequences(#TODO,\n",
        "                               maxlen=#TODO,\n",
        "                               padding=pad,\n",
        "                               value=word_index[\"<PAD>\"])\n",
        "test_data_pad = pad_sequences(#TODO,\n",
        "                              maxlen=#TODO,\n",
        "                              padding=pad,\n",
        "                              value=word_index[\"<PAD>\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quksHiyqjC-o"
      },
      "source": [
        "print(train_data_pad.shape)\n",
        "print(test_data_pad.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6YYEc0bjC-q"
      },
      "source": [
        "#### Padding data 출력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-03-04T06:07:59.449979Z",
          "start_time": "2019-03-04T06:07:58.334795Z"
        },
        "id": "dCI9mcsVjC-r"
      },
      "source": [
        "index = 0\n",
        "print(\"text: {}\\n\".format(decode_review(train_data[index])))\n",
        "print(\"token: {}\\n\".format(train_data[index]))\n",
        "print(\"pad: {}\".format(train_data_pad[index]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KU115TnojC-t"
      },
      "source": [
        "### Create a validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-03-04T06:08:04.189086Z",
          "start_time": "2019-03-04T06:08:04.184027Z"
        },
        "id": "cG6qc-5njC-t"
      },
      "source": [
        "num_val_data = #TODO\n",
        "val_data_pad = train_data_pad[:num_val_data]\n",
        "train_data_pad_partial = train_data_pad[num_val_data:]\n",
        "\n",
        "val_labels = train_labels[:num_val_data]\n",
        "train_labels_partial = train_labels[num_val_data:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CPqHeI9y7g2"
      },
      "source": [
        "### Dataset 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVhh2SOcjC_C"
      },
      "source": [
        "batch_size = #TODO\n",
        "\n",
        "# for train\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((#TODO, #TODO))\n",
        "train_dataset = train_dataset.shuffle(10000).repeat().batch(batch_size=batch_size)\n",
        "print(train_dataset)\n",
        "\n",
        "# for test\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((#TODO, #TODO))\n",
        "test_dataset = test_dataset.batch(batch_size=batch_size)\n",
        "print(test_dataset)\n",
        "\n",
        "# for valid\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((#TODO, #TODO))\n",
        "valid_dataset = valid_dataset.batch(batch_size=batch_size)\n",
        "print(valid_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5KBM5sdjC-v"
      },
      "source": [
        "## Setup hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-03-04T06:08:34.724505Z",
          "start_time": "2019-03-04T06:08:34.720495Z"
        },
        "id": "P1fls3PEjC-w"
      },
      "source": [
        "# Set the hyperparameter set\n",
        "max_epochs = #TODO\n",
        "embedding_size = #TODO\n",
        "vocab_size = #TODO\n",
        "\n",
        "# the save point\n",
        "if use_colab:\n",
        "    checkpoint_dir ='./drive/My Drive/train_ckpt/sentimental/exp1'\n",
        "    if not os.path.isdir(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "else:\n",
        "    checkpoint_dir = 'sentimental/exp1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMG2MOXUjC-y"
      },
      "source": [
        "## Build the model\n",
        "### Embedding layer\n",
        "\n",
        "* embedding-layer는 전체 vocabulary의 갯수(num_words)로 이루어진 index가 `embedding_size`의 *dense vector* 로 변환되는 과정이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-03-04T06:10:48.761441Z",
          "start_time": "2019-03-04T06:10:48.753644Z"
        },
        "id": "0li13tSGjC-1"
      },
      "source": [
        "# TODO\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Embedding(#TODO, #TODO, mask_zero=True,)) # 10000, 256\n",
        "\n",
        "# model.add 를 통해 자유롭게 모델을 만들어보세요.\n",
        "# TODO\n",
        "model.add(layers.GRU(#TODO)) # LSTM,bidirectional\n",
        "\n",
        "# TODO\n",
        "model.add(layers.Dense(#TODO)) # 이진 분류! 0 or 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JC5OGALjC-8"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXObUdM6jC--"
      },
      "source": [
        "### Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-03-04T06:11:19.741901Z",
          "start_time": "2019-03-04T06:11:19.734665Z"
        },
        "id": "Q-KOk-3ujC_A"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(#TODO)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=#TODO,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cruLtRx2jC_C"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qFJhZl6_NI5"
      },
      "source": [
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_dir,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 monitor='val_loss',\n",
        "                                                 mode='auto',\n",
        "                                                 save_best_only=True,\n",
        "                                                 verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-03-04T06:11:57.988951Z",
          "start_time": "2019-03-04T06:11:29.719361Z"
        },
        "id": "waom7QxfjC_E"
      },
      "source": [
        "history = model.fit(#,\n",
        "                    epochs=#,\n",
        "                    validation_data=#,\n",
        "                    steps_per_epoch=#,\n",
        "                    validation_steps=#,\n",
        "                    callbacks=[#,#]\n",
        "                    )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VYoFVsVjC_G"
      },
      "source": [
        "## 모델 테스트\n",
        "* 테스트 데이터셋을 이용해 모델을 테스트해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jiIGyqUvpY_"
      },
      "source": [
        "model.load_weights(checkpoint_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-03-04T05:56:34.572611Z",
          "start_time": "2019-03-04T05:56:34.116Z"
        },
        "id": "K-Z7Lg-TjC_G"
      },
      "source": [
        "results = model.evaluate(test_dataset)\n",
        "# loss\n",
        "print(\"loss value: {:.3f}\".format(results[0]))\n",
        "# accuracy\n",
        "print(\"accuracy value: {:.3f}\".format(results[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avXaOtHsjC_I"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}