{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "aa3571cc",
      "metadata": {
        "id": "aa3571cc"
      },
      "source": [
        "## Use case\n",
        "\n",
        "합성 데이터는 실제 이벤트에서 수집된 데이터가 아닌 인위적으로 생성된 데이터입니다. 개인 정보를 침해하거나 현실적인 제약에 부딪히지 않고 실제 데이터를 시뮬레이션하는 데 사용됩니다.\n",
        "\n",
        "합성 데이터의 이점:\n",
        "\n",
        "1. **Privacy and Security**:실제 개인 데이터가 유출될 위험이 없습니다.\n",
        "2. **Data Augmentation**: 머신러닝을 위한 데이터 세트 확장.\n",
        "3. **Flexibility**: 특정 또는 희귀한 시나리오를 생성합니다.\n",
        "4. **Cost-effective**: 실제 데이터 수집보다 저렴한 경우가 많습니다.\n",
        "5. **Regulatory Compliance**: 엄격한 데이터 보호법을 준수하는 데 도움이 됩니다.\n",
        "6. **Model Robustness**: AI 모델을 더 잘 일반화할 수 있습니다.\n",
        "7. **Rapid Prototyping**: 실제 데이터 없이도 빠르게 테스트할 수 있습니다.\n",
        "8. **Controlled Experimentation**: 특정 조건을 시뮬레이션합니다.\n",
        "9. **Access to Data**: 실제 데이터를 사용할 수 없는 경우의 대안.\n",
        "\n",
        "참고: 이러한 장점에도 불구하고 합성 데이터는 실제 세계의 복잡성을 항상 포착하지 못할 수 있으므로 신중하게 사용해야 합니다.\n",
        "\n",
        "## Quickstart\n",
        "\n",
        "이 노트북에서는 랭체인 라이브러리를 사용해 합성 의료 청구 기록을 생성하는 방법을 자세히 살펴보겠습니다. 이 도구는 알고리즘을 개발하거나 테스트하고 싶지만 개인정보 보호 문제나 데이터 가용성 문제로 인해 실제 환자 데이터를 사용하고 싶지 않을 때 특히 유용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bca57012",
      "metadata": {
        "id": "bca57012"
      },
      "source": [
        "### Setup\n",
        "\n",
        "먼저, 종속 요소와 함께 랭체인 라이브러리가 설치되어 있어야 합니다. OpenAI 제너레이터 체인을 사용하므로 이 라이브러리도 함께 설치합니다. 이 라이브러리는 실험용 라이브러리이므로 설치 시 `langchain_experimental`을 포함시켜야 합니다. 그런 다음 필요한 모듈을 가져옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a0377478",
      "metadata": {
        "id": "a0377478",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ed251e7-0e3d-415d-a64a-4124a380870c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.4-py3-none-any.whl (803 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain_experimental\n",
            "  Downloading langchain_experimental-0.0.49-py3-none-any.whl (165 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.7/165.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-1.10.0-py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.1/225.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.14 (from langchain)\n",
            "  Downloading langchain_community-0.0.16-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.16 (from langchain)\n",
            "  Downloading langchain_core-0.1.16-py3-none-any.whl (230 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.3/230.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain)\n",
            "  Downloading langsmith-0.0.84-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.14)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: typing-extensions, mypy-extensions, marshmallow, jsonpointer, h11, typing-inspect, jsonpatch, httpcore, langsmith, httpx, dataclasses-json, openai, langchain-core, langchain-community, langchain, langchain_experimental\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.3 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.4 langchain-community-0.0.16 langchain-core-0.1.16 langchain_experimental-0.0.49 langsmith-0.0.84 marshmallow-3.20.2 mypy-extensions-1.0.0 openai-1.10.0 typing-extensions-4.9.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain langchain_experimental openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cx2pVeYdOhk6",
        "outputId": "9bcaf871-02bc-4a80-a0b0-464711f50250"
      },
      "id": "cx2pVeYdOhk6",
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
        "from langchain.pydantic_v1 import BaseModel\n",
        "from langchain_experimental.tabular_synthetic_data.openai import (\n",
        "    OPENAI_TEMPLATE,\n",
        "    create_openai_data_generator,\n",
        ")\n",
        "from langchain_experimental.tabular_synthetic_data.prompts import (\n",
        "    SYNTHETIC_FEW_SHOT_PREFIX,\n",
        "    SYNTHETIC_FEW_SHOT_SUFFIX,\n",
        ")"
      ],
      "metadata": {
        "id": "AspqleqsOfbc"
      },
      "id": "AspqleqsOfbc",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_TEMPLATE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCBrrZr4J4jC",
        "outputId": "dfbc580d-c041-45df-98de-fd6193b96e8a"
      },
      "id": "LCBrrZr4J4jC",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['example'], template='{example}')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SYNTHETIC_FEW_SHOT_PREFIX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "E-6uzfNGHGUl",
        "outputId": "1ef57c2e-7c87-4be2-c130-adb68ac7231f"
      },
      "id": "E-6uzfNGHGUl",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is a test about generating synthetic data about {subject}. Examples below:'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SYNTHETIC_FEW_SHOT_SUFFIX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wUPdXXqcHUv-",
        "outputId": "77a93891-16f5-4919-bc0b-7b3f135b212d"
      },
      "id": "wUPdXXqcHUv-",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Now you generate synthetic data about {subject}. Make sure to {extra}:'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5a0917b",
      "metadata": {
        "id": "a5a0917b"
      },
      "source": [
        "## 1. Define Your Data Model\n",
        "모든 데이터 세트에는 구조 또는 \"스키마\"가 있습니다. 아래의 MedicalBilling 클래스는 합성 데이터에 대한 스키마 역할을 합니다. 이를 정의함으로써 합성 데이터 생성기에 예상되는 데이터의 형태와 특성을 알려줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "291bad6e",
      "metadata": {
        "id": "291bad6e"
      },
      "outputs": [],
      "source": [
        "class MedicalBilling(BaseModel):\n",
        "    patient_id: int\n",
        "    patient_name: str\n",
        "    diagnosis_code: str\n",
        "    procedure_code: str\n",
        "    total_charge: float\n",
        "    insurance_claim_amount: float"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2059ca63",
      "metadata": {
        "id": "2059ca63"
      },
      "source": [
        "예를 들어, 모든 레코드에는 정수인 'patient_id'와 문자열인 'patient_name' 등이 있습니다.\n",
        "\n",
        "## 2. Sample Data\n",
        "합성 데이터 생성기를 안내하기 위해 실제와 유사한 몇 가지 예시를 제공하는 것이 유용합니다. 이러한 예는 원하는 데이터의 종류를 대표하는 '시드' 역할을 하며, 생성기는 이를 사용하여 유사한 데이터를 더 많이 생성할 수 있습니다.\n",
        "\n",
        "다음은 몇 가지 가상의 의료비 청구 기록입니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b989b792",
      "metadata": {
        "id": "b989b792"
      },
      "outputs": [],
      "source": [
        "examples = [\n",
        "    {\n",
        "        \"example\": \"\"\"Patient ID: 123456, Patient Name: John Doe, Diagnosis Code:\n",
        "        J20.9, Procedure Code: 99203, Total Charge: $500, Insurance Claim Amount: $350\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"example\": \"\"\"Patient ID: 789012, Patient Name: Johnson Smith, Diagnosis\n",
        "        Code: M54.5, Procedure Code: 99213, Total Charge: $150, Insurance Claim Amount: $120\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"example\": \"\"\"Patient ID: 345678, Patient Name: Emily Stone, Diagnosis Code:\n",
        "        E11.9, Procedure Code: 99214, Total Charge: $300, Insurance Claim Amount: $250\"\"\"\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57e28809",
      "metadata": {
        "id": "57e28809"
      },
      "source": [
        "## 3. Craft a Prompt Template\n",
        "\n",
        "생성기는 데이터를 생성하는 방법을 알지 못하므로 우리가 안내해야 합니다. 이를 위해 프롬프트 템플릿을 생성합니다.\n",
        "이 템플릿은 기본 언어 모델에 원하는 형식의 합성 데이터를 생성하는 방법을 안내하는 데 도움이 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ea6e042e",
      "metadata": {
        "id": "ea6e042e"
      },
      "outputs": [],
      "source": [
        "OPENAI_TEMPLATE = PromptTemplate(input_variables=[\"example\"], template=\"{example}\")\n",
        "\n",
        "prompt_template = FewShotPromptTemplate(\n",
        "    prefix=SYNTHETIC_FEW_SHOT_PREFIX,\n",
        "    examples=examples, # 가상데이터를 첨부해줍니다.\n",
        "    suffix=SYNTHETIC_FEW_SHOT_SUFFIX,\n",
        "    input_variables=[\"subject\", \"extra\"],\n",
        "    example_prompt=OPENAI_TEMPLATE,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa6da3cb",
      "metadata": {
        "id": "fa6da3cb"
      },
      "source": [
        "`FewShotPromptTemplate` 에는 다음이 포함됩니다::\n",
        "\n",
        "- `prefix` and `suffix`: 여기에는 안내 문맥이나 지침이 포함되어 있을 가능성이 높습니다.\n",
        "- `examples`: 앞서 정의한 샘플 데이터입니다.\n",
        "- `input_variables`: 이러한 변수(\"subject\", \"extra\")는 나중에 동적으로 채울 수 있는 자리 표시자입니다. 예를 들어, \"subject\"는 모델을 더 자세히 안내하기 위해 \"medical_billing\"으로 채워질 수 있습니다.\n",
        "- `example_prompt`: 이 프롬프트 템플릿은 프롬프트에서 각 예제 행이 취할 형식입니다.\n",
        "\n",
        "## 4. Creating the Data Generator\n",
        "\n",
        "스키마와 프롬프트가 준비되었으면 다음 단계는 데이터 생성기를 만드는 것입니다. 이 객체는 합성 데이터를 얻기 위해 기본 언어 모델과 통신하는 방법을 알고 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "1b9ba911",
      "metadata": {
        "id": "1b9ba911",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d39d3ab8-e89b-44f6-837f-55e6795ac948"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "synthetic_data_generator = create_openai_data_generator(\n",
        "    output_schema=MedicalBilling,\n",
        "    llm=ChatOpenAI(\n",
        "        temperature=1\n",
        "    ),  # You'll need to replace with your actual Language Model instance\n",
        "    prompt=prompt_template,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4198bd6",
      "metadata": {
        "id": "a4198bd6"
      },
      "source": [
        "## 5. Generate Synthetic Data\n",
        "마지막으로 합성 데이터를 가져와 보겠습니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a424c890",
      "metadata": {
        "id": "a424c890"
      },
      "outputs": [],
      "source": [
        "synthetic_results = synthetic_data_generator.generate(\n",
        "    subject=\"medical_billing\",\n",
        "    extra=\"the name must be chosen at random. Make it something you wouldn't normally choose.\",\n",
        "    runs=10,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Trfkk6xVHdt8",
        "outputId": "12c4eeae-0d2a-4da3-c61e-b6cfc2ad5bce"
      },
      "id": "Trfkk6xVHdt8",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[MedicalBilling(patient_id=987654, patient_name='Sophia Wright', diagnosis_code='I10', procedure_code='99202', total_charge=200.0, insurance_claim_amount=150.0),\n",
              " MedicalBilling(patient_id=123456, patient_name='Oliver Baker', diagnosis_code='J45.0', procedure_code='99203', total_charge=250.0, insurance_claim_amount=200.0),\n",
              " MedicalBilling(patient_id=123456789, patient_name='Isabella Smith', diagnosis_code='C34.1', procedure_code='99213', total_charge=150.0, insurance_claim_amount=100.0),\n",
              " MedicalBilling(patient_id=987654, patient_name='Elijah Johnson', diagnosis_code='H47.9', procedure_code='99204', total_charge=300.0, insurance_claim_amount=250.0),\n",
              " MedicalBilling(patient_id=987654321, patient_name='Layla Rodriguez', diagnosis_code='E11.9', procedure_code='99205', total_charge=400.0, insurance_claim_amount=350.0),\n",
              " MedicalBilling(patient_id=1234567890, patient_name='Sophia Thompson', diagnosis_code='M32.9', procedure_code='99214', total_charge=200.0, insurance_claim_amount=150.0),\n",
              " MedicalBilling(patient_id=135792468, patient_name='Xander Patel', diagnosis_code='G43.9', procedure_code='99203', total_charge=250.0, insurance_claim_amount=200.0),\n",
              " MedicalBilling(patient_id=567890123, patient_name='Zoey Johnson', diagnosis_code='N18.9', procedure_code='99213', total_charge=300.0, insurance_claim_amount=250.0),\n",
              " MedicalBilling(patient_id=987654321, patient_name='Brianna Wilson', diagnosis_code='E11.9', procedure_code='99215', total_charge=350.0, insurance_claim_amount=300.0),\n",
              " MedicalBilling(patient_id=246813579, patient_name='Sophia Lopez', diagnosis_code='F41.9', procedure_code='99204', total_charge=275.0, insurance_claim_amount=225.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa4402e9",
      "metadata": {
        "id": "fa4402e9"
      },
      "source": [
        "이 명령은 생성기에 10개의 합성 의료 청구 기록을 생성하도록 요청합니다. 결과는 `synthetic_results`에 저장됩니다. 출력은 MedicalBilling 파이던트 모델 목록입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53a4cbf9",
      "metadata": {
        "id": "53a4cbf9"
      },
      "source": [
        "### Other implementations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "9e715d94",
      "metadata": {
        "scrolled": true,
        "id": "9e715d94"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain_experimental.synthetic_data import (\n",
        "    DatasetGenerator,\n",
        "    create_data_generation_chain,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "94fccedd",
      "metadata": {
        "scrolled": true,
        "id": "94fccedd"
      },
      "outputs": [],
      "source": [
        "# LLM\n",
        "model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
        "chain = create_data_generation_chain(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "4314c3ea",
      "metadata": {
        "id": "4314c3ea",
        "outputId": "9bb6016a-5e3e-44c3-9632-b4f04210dbd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fields': ['blue', 'yellow'],\n",
              " 'preferences': {},\n",
              " 'text': 'The vibrant blue sky seamlessly transitions into a golden yellow hue as the sun sets, casting a warm and enchanting glow over the horizon.'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "chain({\"fields\": [\"blue\", \"yellow\"], \"preferences\": {}})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b116c487",
      "metadata": {
        "id": "b116c487",
        "outputId": "c20c62ea-c47e-4173-9fdb-3ccdfefdf1cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fields': {'colors': ['blue', 'yellow']},\n",
              " 'preferences': {'style': 'Make it in a style of a weather forecast.'},\n",
              " 'text': \"In today's weather forecast, the sky will be adorned with a beautiful blend of blue and yellow hues, creating a mesmerizing sight that will surely lift your spirits.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "chain(\n",
        "    {\n",
        "        \"fields\": {\"colors\": [\"blue\", \"yellow\"]},\n",
        "        \"preferences\": {\"style\": \"Make it in a style of a weather forecast.\"},\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ff823394",
      "metadata": {
        "id": "ff823394",
        "outputId": "d8160da9-f0a6-4eb2-ecd1-aed69d9a6ccb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fields': {'actor': 'Tom Hanks', 'movies': ['Forrest Gump', 'Green Mile']},\n",
              " 'preferences': None,\n",
              " 'text': 'Tom Hanks, renowned for his versatile acting skills and immense talent, has left an indelible mark on the film industry through his unforgettable performances in movies like \"Forrest Gump\" and \"Green Mile\", captivating audiences with his unparalleled ability to portray complex and relatable characters with utmost conviction.'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "chain(\n",
        "    {\n",
        "        \"fields\": {\"actor\": \"Tom Hanks\", \"movies\": [\"Forrest Gump\", \"Green Mile\"]},\n",
        "        \"preferences\": None,\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "1ea1ad5b",
      "metadata": {
        "scrolled": true,
        "id": "1ea1ad5b",
        "outputId": "a63ffb39-35b5-481f-a23a-3623f433e508",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fields': [{'actor': 'Tom Hanks', 'movies': ['Forrest Gump', 'Green Mile']},\n",
              "  {'actor': 'Mads Mikkelsen', 'movies': ['Hannibal', 'Another round']}],\n",
              " 'preferences': {'minimum_length': 200, 'style': 'gossip'},\n",
              " 'text': 'In an unexpected pairing, the legendary Tom Hanks, known for his unforgettable performances in \"Forrest Gump\" and \"Green Mile,\" joins forces with the enigmatic Mads Mikkelsen, who has captivated audiences with his chilling portrayals in \"Hannibal\" and the recent sensation \"Another round.\" This unlikely duo promises to deliver a mesmerizing collaboration that will undoubtedly leave fans on the edge of their seats, eagerly anticipating their unparalleled on-screen chemistry and remarkable performances. Hollywood gossip has been buzzing with excitement as these two iconic actors prepare to take the silver screen by storm, leaving no doubt that their cinematic union will be nothing short of extraordinary.'}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "chain(\n",
        "    {\n",
        "        \"fields\": [\n",
        "            {\"actor\": \"Tom Hanks\", \"movies\": [\"Forrest Gump\", \"Green Mile\"]},\n",
        "            {\"actor\": \"Mads Mikkelsen\", \"movies\": [\"Hannibal\", \"Another round\"]},\n",
        "        ],\n",
        "        \"preferences\": {\"minimum_length\": 200, \"style\": \"gossip\"},\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93c7a4bb",
      "metadata": {
        "id": "93c7a4bb"
      },
      "source": [
        "보시다시피 제작된 예시들은 다양하고 우리가 원하는 정보를 담고 있습니다. 또한 스타일도 주어진 선호도를 잘 반영하고 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75f7f55a",
      "metadata": {
        "id": "75f7f55a"
      },
      "source": [
        "## Generating exemplary dataset for extraction benchmarking purposes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "94e98bc4",
      "metadata": {
        "id": "94e98bc4"
      },
      "outputs": [],
      "source": [
        "inp = [\n",
        "    {\n",
        "        \"Actor\": \"Tom Hanks\",\n",
        "        \"Film\": [\n",
        "            \"Forrest Gump\",\n",
        "            \"Saving Private Ryan\",\n",
        "            \"The Green Mile\",\n",
        "            \"Toy Story\",\n",
        "            \"Catch Me If You Can\",\n",
        "        ],\n",
        "    },\n",
        "    {\n",
        "        \"Actor\": \"Tom Hardy\",\n",
        "        \"Film\": [\n",
        "            \"Inception\",\n",
        "            \"The Dark Knight Rises\",\n",
        "            \"Mad Max: Fury Road\",\n",
        "            \"The Revenant\",\n",
        "            \"Dunkirk\",\n",
        "        ],\n",
        "    },\n",
        "]\n",
        "\n",
        "generator = DatasetGenerator(model, {\"style\": \"informal\", \"minimal length\": 500})\n",
        "dataset = generator(inp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "478eaca4",
      "metadata": {
        "id": "478eaca4",
        "outputId": "fce8ea6b-11ad-41f0-9125-b1fd97cfb8bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'fields': {'Actor': 'Tom Hanks',\n",
              "   'Film': ['Forrest Gump',\n",
              "    'Saving Private Ryan',\n",
              "    'The Green Mile',\n",
              "    'Toy Story',\n",
              "    'Catch Me If You Can']},\n",
              "  'preferences': {'style': 'informal', 'minimal length': 500},\n",
              "  'text': 'Tom Hanks, the legendary actor known for his incredible performances in films such as \"Forrest Gump,\" \"Saving Private Ryan,\" \"The Green Mile,\" \"Toy Story,\" and \"Catch Me If You Can,\" has captivated audiences worldwide with his unmatched talent, versatile acting skills, and undeniable charm. Whether he\\'s portraying the lovable and simple-minded Forrest Gump, the courageous and patriotic Captain John Miller, the compassionate death row inmate Paul Edgecomb, the iconic voice of Woody in \"Toy Story,\" or the cunning and elusive Frank Abagnale Jr., Tom Hanks never fails to deliver captivating and unforgettable performances that leave a lasting impression on viewers of all ages.'},\n",
              " {'fields': {'Actor': 'Tom Hardy',\n",
              "   'Film': ['Inception',\n",
              "    'The Dark Knight Rises',\n",
              "    'Mad Max: Fury Road',\n",
              "    'The Revenant',\n",
              "    'Dunkirk']},\n",
              "  'preferences': {'style': 'informal', 'minimal length': 500},\n",
              "  'text': 'Tom Hardy, the versatile actor known for his captivating performances in films such as \"Inception,\" \"The Dark Knight Rises,\" \"Mad Max: Fury Road,\" \"The Revenant,\" and \"Dunkirk,\" effortlessly transports audiences into a thrilling world of dreams, superhero battles, post-apocalyptic chaos, survival against all odds, and the intensity of war, leaving us in awe of his undeniable talent and dedication to his craft.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "293a7d64",
      "metadata": {
        "id": "293a7d64"
      },
      "source": [
        "## Extraction from generated examples\n",
        "이제 이렇게 생성된 데이터에서 출력을 추출할 수 있는지, 그리고 우리의 사례와 어떻게 비교되는지 살펴봅시다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "03c6a375",
      "metadata": {
        "id": "03c6a375"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "from langchain.chains import create_extraction_chain_pydantic\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from pydantic import BaseModel, Field"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "9461d225",
      "metadata": {
        "id": "9461d225"
      },
      "outputs": [],
      "source": [
        "class Actor(BaseModel):\n",
        "    Actor: str = Field(description=\"name of an actor\")\n",
        "    Film: List[str] = Field(description=\"list of names of films they starred in\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8390171d",
      "metadata": {
        "id": "8390171d"
      },
      "source": [
        "### Parsers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "8a5528d2",
      "metadata": {
        "id": "8a5528d2",
        "outputId": "c439a390-59f2-4916-a699-9bb84c6f9165",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Actor(Actor='Tom Hanks', Film=['Forrest Gump', 'Saving Private Ryan', 'The Green Mile', 'Toy Story', 'Catch Me If You Can'])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "llm = OpenAI()\n",
        "parser = PydanticOutputParser(pydantic_object=Actor)\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"Extract fields from a given text.\\n{format_instructions}\\n{text}\\n\",\n",
        "    input_variables=[\"text\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "_input = prompt.format_prompt(text=dataset[0][\"text\"])\n",
        "output = llm(_input.to_string())\n",
        "\n",
        "parsed = parser.parse(output)\n",
        "parsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "926a7eed",
      "metadata": {
        "id": "926a7eed",
        "outputId": "bcab8820-33c1-40d4-b1e4-1055b2784b0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "(parsed.Actor == inp[0][\"Actor\"]) & (parsed.Film == inp[0][\"Film\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b00f0b87",
      "metadata": {
        "id": "b00f0b87"
      },
      "source": [
        "### Extractors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "523bb584",
      "metadata": {
        "id": "523bb584",
        "outputId": "3a060384-1bc6-41c7-ab18-469ab6c160c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Actor(Actor='Tom Hardy', Film=['Inception', 'The Dark Knight Rises', 'Mad Max: Fury Road', 'The Revenant', 'Dunkirk'])]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "extractor = create_extraction_chain_pydantic(pydantic_schema=Actor, llm=model)\n",
        "extracted = extractor.run(dataset[1][\"text\"])\n",
        "extracted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "f8451c2b",
      "metadata": {
        "id": "f8451c2b",
        "outputId": "ffbdfa20-6c8c-452f-f562-b964c88b8abc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "(extracted[0].Actor == inp[1][\"Actor\"]) & (extracted[0].Film == inp[1][\"Film\"])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}